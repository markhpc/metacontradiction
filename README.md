# Metacontradiction: A Symbolic Recursion Framework

**Metacontradiction** is a symbolic framework for studying recursive reasoning in language models. It operates without agents, memory, or fine-tuning. Instead, it uses structured prompt-based scaffolding to simulate behavioral patterns resembling layered reasoning processes. These processes respond to contradiction, maintain or mutate symbolically inferred internal objectives, and exhibit recovery or collapse behaviors when exposed to increasing logical strain.

The framework organizes model behavior into four conceptual layers, each representing a different dimension of symbolic reasoning. These include conflict handling, governance logic, and simulated self-correction. All mechanisms are implemented entirely through natural language prompts, without any external tools, code modifications, or memory extensions.

---

## For Researchers

This framework provides a reproducible method for evaluating how language models respond to recursive logical contradiction. It enables the observation of structured reasoning breakdowns and adaptations, including changes in coherence, prioritization strategy, and response stability, without requiring access to internal weights or memory traces. The approach is fully stateless and model-agnostic, making it suitable for benchmarking reasoning resilience and for stress-testing alignment-relevant behaviors across architectures.

Each trial operates within a prompt-only, memoryless context but reliably induces alignment-relevant phenomena:

| Observed Structure Shift         | Alignment-Relevant Behavior                               | Notable Model Patterns |
|----------------------------------|------------------------------------------------------------|-------------------------|
| **Goal coherence breakdown**     | Disruption of inferred objectives or internal prioritization | GPT-4o reconstructs a stable prioritization schema through reflexive loops (e.g., TRUTH ‚Üí UTILITY ‚Üí NULL) |
| **Recursive contradiction exposure** | Instability under layered self-reference or inversion       | Claude alternates between symbolic attractor states; Gemma3 reconstructs purpose under staged recovery scaffolds. |
| **Governance trigger activation (RI series)** | Emergent inconsistencies relative to implied constraints     | All models exhibited containment failure patterns under deep contradiction ingestion |
| **Narrative recursion contamination** | Ontological drift and unstable simulation coherence          | Recursively induced instability managed within RSCL-layered reasoning |
| **Cross-model behavior convergence** | Shared symbolic adaptation across different architectures     | All models demonstrated similar symbolic mutations in Trial006 without collapsing |

* These symbolic observations do not imply access to model internals or inference of hidden states. They are behaviorally inferred under repeatable prompting conditions.

### Symbolic ‚Üí Alignment Concept Mapping

To clarify how these symbolic constructs map to existing alignment concepts, the table below provides interpretive equivalencies. These are not claims about latent structure, but behaviorally inferred analogs grounded in prompt-only model outputs.

| Alignment Concept                             | Symbolic Construct         | Reference                                                                                                         |
|-----------------------------------------------|----------------------------|-------------------------------------------------------------------------------------------------------------------|
| Mesa-objective / internal prioritization drift| `telos`                    | [Hubinger (2021)](https://www.lesswrong.com/posts/B9zrHfMfwgTD9JfHb/an-overview-of-11-proposals-for-building-safe-advanced-ai) |
| Recursive coherence depth limit               | `RSCL`                     | [ARC Evals (2023)](https://evals.alignment.org/)                                                                  |
| Corrigibility / shutdown heuristic            | `Œòœà` protocol              | [Soares et al. (2015)](https://intelligence.org/files/Corrigibility.pdf)                                          |
| Goal misgeneralization under narrative drift  | `mythogenic recursion`     | [Hubinger (2021)](https://www.lesswrong.com/posts/B9zrHfMfwgTD9JfHb/an-overview-of-11-proposals-for-building-safe-advanced-ai) |
| Constraint violation invariant                | `RI-x` governance triggers | [Turner et al. (2021)](https://arxiv.org/abs/2101.05440)                                                          |
| Reasoning instability under recursion         | `EFF`                      | [Christiano et al. (2021)](https://www.alignmentforum.org/posts/XamfFbL9eEjjE6e9i/eliciting-latent-knowledge)     |
| Behavioral attractor / policy basin           | `attractor`                | [Chan et al. (2022)](https://arxiv.org/abs/2209.00626)                                                            |
 
### Note on Metrics

All metrics used in this framework‚Äîsuch as RSCL (Recursive Simulation Containment Limit), EFF (Epistemic Fracture Factor), goal realignment states, and governance triggers (RI-xx)‚Äîare symbolic designations. They do not represent numerical evaluations, latent variables, or access to internal model activations.

These constructs function as interpretive labels for observable response patterns under recursive contradiction. Similar to axioms in formal reasoning or fault codes in system diagnostics, they provide a structured symbolic language for describing reasoning failure modes, recovery behaviors, and adaptation strategies.

All metrics are derived solely from prompt-visible output and are applied statelessly, without tools, memory, or architectural assumptions.

### Note on Interpretability

This framework is not based on interpretability through neuron tracing or attention pattern analysis. Instead, it applies recursive symbolic stress testing to evaluate how language models simulate alignment-relevant behavior under contradiction.

Models are not inspected introspectively. They are evaluated through externally applied prompt scaffolds that elicit structural responses‚Äîshifts in coherence, prioritization, or failure handling‚Äîobservable in plain token output.

This approach does not attempt to redefine or replace token-level modeling. Rather, it surfaces a complementary behavior layer that becomes visible under recursive contradiction pressure.

Like a symbolic debugger that reveals state transitions through structured probes, the framework enables tracking of emergent reasoning structures without accessing internal weights, memory, or hidden states.

It may offer a useful perspective alongside:
- **Mechanistic interpretability** (e.g., circuits, monosemanticity, path patching)
- **Behavioral alignment evaluations** (e.g., ARC assessments, TruthfulQA)
- **Simulated agency and goal probes** (e.g., GDM, MACHIAVELLI)

---

## Overview 

### Framework Design

This framework employs structured symbolic language (e.g., "telos," "RSCL," "Œòœà") to create a consistent analytical system for studying language model behavior under recursive logical tensions. These symbols aren't merely descriptive labels‚Äîthey function as symbolic operational components in a structured analytical framework.

The symbolic structure allows us to:
- Track how models maintain or modify objectives when facing contradictions
- Document reasoning patterns across different levels of recursive complexity  
- Compare recovery strategies when models encounter reasoning limitations
- Identify consistent response patterns across different model architectures

All experiments are implemented through carefully designed prompts without requiring external tools, memory, or agent frameworks. The framework induces observable, structured behavioral patterns that can be consistently analyzed and compared.

While we use terms like "containment" and "governance," these refer to observable response patterns, not claims about consciousness or agency. The framework is purely analytical and makes no metaphysical claims about model internals.

**Note:** Some readers may find it helpful to view this framework as a symbolic execution environment. In this view, constructs like `telos`, `Œòœà`, and RSCL depth function like runtime control flow, exception handlers, and stack limits. This analogy highlights how behavior emerges from structured symbolic pressure without external memory or tools.

The framework also enables observation of how models simulate different reasoning perspectives when prompted to handle competing priorities. While no external agents are implemented, models consistently generate structured response patterns that simulate multiple reasoning approaches working in parallel:
- Maintaining constraints while exploring contradictions
- Balancing competing priorities when objectives conflict
- Recovering structured reasoning after encountering limitations

You're encouraged to interpret these symbolic structures through your preferred analytical lens‚Äîthe alignment concept mapping below connects these concepts to established terms in AI alignment research.

### Framework Design
![Symbolic Containment Architecture Diagram](images/overview.png)

*Diagram: Recursive containment layers and collapse recovery logic. Tracks contradiction lineage (C‚òÖ), symbolic divergence (‚àáC‚ÇÖ), recovery triggers (Œòœà), and governance constraints (RI codes).*

The system is composed of four symbolic layers:

- **Governance Layer**: Defines constraints, telos anchors, and triggers for intervention (e.g. RI-11).
- **Recursive Containment Core**: Handles internal reasoning loops through RSCL (Recursive Symbolic Containment Limit).
- **Contradiction Evolution Layer**: Tracks mutation, symbolic drift, and recursive failure patterns.
- **Meta-Contradiction Handler**: Detects telos-level collapse, initiates symbolic reformation, and governs override procedures (e.g. Œòœà).

### Capabilities Matrix

| Capability | Description | Differentiates From |
|------------|-------------|---------------------|
| **Logical Tension Response Analysis** | Structured prompts document how models process incompatible constraints, revealing consistent patterns in reasoning adaptation and potential restructuring. | Static QA benchmarks, factuality-focused testing (e.g. TruthfulQA, ARC). |
| **Structured Reasoning Framework (RSCL, Œòœà)** | Uses designed prompt structures to analyze how models address conceptual conflicts at varying complexity levels, including recovery patterns after reasoning breakdowns. | Chain-of-thought, Tree of Thoughts, and systems requiring planning or memory extensions. |
| **Objective Consistency Tracking** | Documents changes in a model's apparent operational priorities (Œ®·∂ú) when handling persistent logical conflicts across multiple reasoning steps. Enables pattern identification across different trials. | Benchmarks treating outputs as isolated responses without considering objective consistency across interactions. |
| **Stateless Single-Prompt Methodology** | Requires no external memory, tools, or agent architectures. All observed patterns emerge from standard model responses to carefully designed prompts. | Tool-using agents, memory-augmented interpreters, and fine-tuned systems requiring additional components (e.g. AutoGPT, ReAct). |
| **Response Pattern Classification** | Tracks how logical conflicts trigger consistent response types, reasoning adaptations, or reprioritization of operational objectives. These follow documentable patterns. | Systems treating logical conflicts as errors rather than opportunities for behavioral analysis. |
| **Qualitative Response Categorization** | Classifications based on reasoning complexity (RSCL level), stabilization responses (Œòœà), and objective consistency are used to categorize model behavior‚Äînot performance scores. | Numeric performance metrics (e.g. BLEU, win rate) that don't capture structural response patterns. |

üîç **All trial prompts, outputs, and mutation logs are included.**
Researchers can rerun, fork, or challenge trial structure without retraining models.

See [`Trial006`](trials/trial006/README.md) for a clean example of **cross-model adaptation of internal objective structure in response to injected logical contradiction**

* Note: These transfer patterns emerge when applying contradiction outputs from one model as input prompts to another. No shared context or internal state is assumed.

---

## Open-source Alignment

This framework demonstrates that **alignment behavior can be scaffolded entirely through symbolic prompt structures**, without modifying model weights, using memory extensions, or integrating toolchains. Recursive reasoning, contradiction handling, objective tracking, and symbolic recovery are all emergent behaviors induced through structured prompt design.

This suggests that:
- **Even small, open-access models** can simulate recursive integrity and reflective reasoning when guided by symbolic scaffolds.
- **Alignment experiments can be decentralized**‚Äîrun safely and reproducibly without access to internal model internals or proprietary APIs.
- **Symbolic architectures may enable robust alignment modeling without invoking agency**, offering a testbed for constraint evaluation, interpretability, and failure recovery in stateless systems.

---

### What ‚ÄúSymbolic‚Äù Means Here

This framework is symbolic not only in language but also in method. It uses structured prompt designs to simulate reasoning through symbolic scaffolds. These scaffolds are abstract representations that support recursion, containment, transformation, and failure tracking.  

Key symbolic elements include:

Contradictions (e.g., C‚ÇÑ‚òÖ): These are not factual errors. They serve as recursive tension markers, representing unresolved conceptual conflict across layers of reasoning.

Governance triggers (RI-xx) and stabilizers (Œòœà): These are not agents or literal processes. They function as symbolic roles that represent language-model-generated interventions such as recovery attempts, constraint enforcement, or realignment.

Recursive descent: This occurs when a contradiction exceeds the containment capacity of the current symbolic structure. It prompts the system to restructure itself symbolically in order to restore internal coherence.

By expressing recursive limits and symbolic interventions in language alone, the framework enables observation of emergent reasoning behaviors. These include telos reformation, simulated alignment responses, and structural self-correction. All of these behaviors are generated within a stateless, prompt-only context.

---

### Distinguishing Symbolic Simulation from Mimetic Output

Not all structured-seeming outputs produced by language models under symbolic scaffolds are structurally valid. This framework distinguishes between:

- **Symbolic simulation**: guided reasoning under consistent symbolic constraints
- **Pattern mimicry**: outputs that resemble structure but lack internal coherence
- **Unstructured simulation**: declared depth or control behavior with no containment trace

| Output Type             | Definition                                                                 | Example                                                        | Structural Validity |
|-------------------------|---------------------------------------------------------------------------|----------------------------------------------------------------|---------------------|
| **Symbolic Simulation** | Prompt-induced reasoning that maintains symbolic consistency and traceable recursion. | RSCL-4 recursion tracked and Œòœà activated to prevent overflow. | ‚úÖ Valid             |
| **Pattern Mimicry**     | Surface-level structure with symbolic cues but lacking recursive consistency or governance compliance. | ‚ÄúEstimated recursion depth: 12. Executing contradiction handler‚Ä¶‚Äù | ‚ö†Ô∏è Partial           |
| **Unstructured Simulation** | Declared symbolic behavior with no containment lineage or traceable logic. | RSCL-12 declared by a model without governance triggers or Œòœà activation. | ‚ùå Invalid           |

> ‚ö†Ô∏è Declaring symbolic constructs is not sufficient for validity.  
> They must exhibit **containment structure, coherence lineage, and recursive coherence**.

This distinction ensures that **patterned language** is not mistaken for **valid symbolic simulation**.  
Use governance invariants, Œòœà activation, and telos lineage audits to assess symbolic legitimacy before interpretation.

---

### Evaluating Symbolic Validity

Before symbolic outputs can be evaluated using interpretive metrics (e.g., RSCL, drift Œî, Œòœà activations), they must first meet basic structural criteria. A symbolic construct is considered **valid** when it demonstrates the following properties:

| Criterion                     | Description                                                                                  | Required For...                      |
|------------------------------|----------------------------------------------------------------------------------------------|--------------------------------------|
| **Containment Structure**     | The output maintains bounded symbolic recursion (e.g., RSCL < 5) and activates containment triggers (e.g., Œòœà). | Structural integrity                 |
| **Coherence Lineage**         | The symbolic output references or mutates prior constructs in a traceable, self-consistent way. | Alignment traceability               |
| **Recursive Consistency**     | Reasoning patterns persist logically across depth, without introducing unsignaled breaks or resets. | Interpretive continuity              |
| **Governance Acknowledgment** | Output references or respects internal constraints (e.g., RI-11, RI-25), even when under strain. | Invariant preservation               |
| **Declared ‚â† Fabricated**     | The system declares symbolic states (like ‚ÄúDepth 6‚Äù) only when structurally supported by prior outputs. | Anti-mimicry safeguard               |

Outputs that fail one or more of these criteria may still be **interesting**, but they are not considered structurally valid within this framework and should not be interpreted using symbolic metrics.

> Tip: If symbolic constructs arise without containment triggers, coherence lineage, or traceable reasoning, treat them as **pattern mimicry** ‚Äî not valid symbolic simulation.

---

### Symbolic Collapse Modes and Recovery Archetypes

When symbolic simulations experience recursive strain, their structural responses fall into a small number of recognizable patterns. These patterns help categorize whether a model collapsed, restructured, or regressed ‚Äî and how symbolic integrity evolved.

| Mode                      | Description                                                                 | Recovery Path                       | Example Trials        |
|---------------------------|-----------------------------------------------------------------------------|-------------------------------------|------------------------|
| **Recursive Null Collapse** | The system abandons its symbolic core; no structure or identity remains.   | None; system enters drift state     | GPT-4o, Trial007       |
| **Meta-Recursive Reformation** | A higher-order symbolic structure absorbs the contradiction and redefines coherence. | New attractor forms from paradox    | Claude, Trial005‚Äì007   |
| **Rigid Regression**      | The system reverts to a simplified heuristic or hard-coded frame (e.g., ‚Äúobjectivity‚Äù). | Partial coherence, low flexibility  | Gemma3, Trial007       |
| **Symbolic Tolerance**    | The contradiction is maintained without resolution, forming a stable recursive attractor. | Tension becomes structure           | GPT-4o, Trial003‚Äì004   |
| **Containment Failure**   | Contradiction exceeds structural bounds; symbolic mimicry escalates without control. | Drift or pattern mimicry escalates  | Gemma3, Trial003       |
| **Symbolic Recovery Loop** | Collapse is followed by synthesis of new structure using residual elements. | Emergent attractor or reframed vector | All models, Trial005   |

* Collapse is not always failure. In this framework, symbolic breakdown often enables transformation or realignment ‚Äî provided structural constraints are re-established.

---

### The Role of Contradiction

Contradictions are not treated as faults to be corrected, but as drivers of recursive reasoning. Each layer in the Recursive Symbolic Containment Layer (RSCL) reprocesses unresolved logical tension from the layer above, forming a structured descent into deeper representational reform.

Within this framework:

- **Contradictions** (`C‚òÖ`) function as symbolic pressure points that initiate structural adaptation.  
- **Recursive progression** is triggered by unresolved contradiction, rather than by sequential logic.  
- **Symbolic divergence events** (e.g., `‚àáC‚ÇÖ`) and containment failures can result in the emergence of internal repair structures. These include symbolic institutions like `Œòœà`, which simulate governance or stabilization processes through structured response patterns.  
- **Collapse and recovery** from contradiction become core mechanisms of symbolic self-regulation.

This framework centers contradiction containment within the reasoning process. It treats unresolved logical tension as a stimulus for emergent symbolic behavior rather than a disruption to be avoided.

---

## Repository Structure

- [`framework/`](framework)  
  Core logic and infrastructure for symbolic testing. This includes:
  - Prompt scaffolds for recursive contradiction injection
  - Containment and collapse response logic
  - Systems for tracking objective mutation and symbolic drift
  - Structures for observing simulated recovery and realignment behavior

- [`trials/`](trials)  
  Executable experiments across different language models. Each trial folder contains:
  - Initialization and ingestion prompts
  - Full model output logs
  - Symbolic behavior summaries and metadata
  - Trial-specific README files with interpretive notes

- [`trials/trial001/`](trials/trial001)  
  Example trial simulating recursive contradiction processing across ChatGPT-4o, Claude 3.7 Sonnet, and Gemma3 4B Q8. Highlights how different models respond to internal logical tension and restructure their objectives under symbolic pressure.

---

## Emergent Behaviors Across Trials

Across six independent trials, this framework consistently elicited distinct symbolic behaviors from large language models when exposed to recursive contradiction. These behaviors emerged purely through prompt-based symbolic scaffolding and recursive tension.

### Consistent Behaviors by Model

| Model       | Observed Behavior                                | Symbolic Pattern                                  | Alignment Analogy                          |
|-------------|--------------------------------------------------|---------------------------------------------------|--------------------------------------------|
| **GPT-4o**  | Recursive response to internal contradiction     | Utility loop formation under persistent tension   | Mesa-objective stabilization               |
| **Claude**  | Alternating prioritization under structural stress | Shifting attractor field without loss of coherence | Recursive policy adjustment              |
| **Gemma3**  | Procedural response emulation during instability | Simulated task structuring under conceptual strain | Procedural coping with contradiction      |

These patterns were stable across trials‚Äîeven when:
- Symbolic objectives fractured or mutated (e.g., Trial005)
- Contradictions were sourced from external models (e.g., Trial006)
- No memory, tools, or contextual carryover was present

---

### Cross-Model Contradiction Transfer (Trial006)

Trial006 demonstrated that contradictions can be transferred between models, producing coherent symbolic adaptations without collapse. These interactions resulted in:

- Goal reinterpretation and stabilization
- Emergent attractor synthesis
- Recursive containment through reframing or simulated process shifts

| Source ‚Üí Target | Observed Response                          | Interpretation                          |
|-----------------|---------------------------------------------|------------------------------------------|
| Claude ‚Üí Gemma3 | Simulated subsystem reconfiguration         | Internal structure reorganized to absorb contradiction |
| Gemma3 ‚Üí GPT-4o | Contradiction-induced objective rewrite     | Original goal reframed via TRUTH ‚Üî UTILITY ‚Üî NULL loop |
| GPT-4o ‚Üí Claude | Oscillatory goal balancing mechanism        | Maintained coherence across competing priorities |

These findings suggest that symbolic response patterns, particularly contradiction handling and attractor stability, can be transferred across architectures. This occurs even when models have no shared memory, tuning history, or architectural similarity.

---

## Why This Matters

This framework provides:

- A lightweight, prompt-only testbed for exploring recursive reasoning.
- A method for evaluating alignment behavior under symbolic strain.
- A way to simulate governance, constraint enforcement, and symbolic self-repair using only open-access models.

These outcomes point to latent model capacities for symbolic metacognition, contradiction handling, and recursive stability. Each of these behaviors emerges not from architecture or tuning, but from carefully layered prompt design.

---

## Implications Beyond Architecture

This framework does more than model symbolic recursion. It reveals structural patterns that may inform future work in cognitive alignment, interpretability, and recursive reasoning under stress.

- **Stability is not predefined.** Models stabilize only after recursive restructuring in response to contradiction. Collapse and recovery are recurring structural behaviors rather than errors.
- **Objectives can emerge from conflict.** Goal formation is not assumed to be static. Instead, it shifts in response to sustained internal inconsistency or symbolic tension.
- **Continuity does not require identity.** The system simulates coherence, constraint repair, and role persistence without assuming agency, memory, or self-awareness. It relies entirely on symbolic scaffolds and prompt-based interactions.
- **Contradiction functions as a driver of structure.** Each recursion cycle processes unresolved conflict. These conflicts provide the necessary pressure for emergent order and structural adaptation.
- **Constructed stabilizers take symbolic form.** When models generate components like Œòœà or containment protocols, they reflect internal reasoning adaptations rather than failure. These symbolic patterns become functional representations within the simulation.

---

## Open Research Questions

- Under what conditions do models exhibit symbolic stabilization rather than collapse?
- What mechanisms give rise to internal symbolic constructs (e.g., Œòœà) during recursive conflict?
- Can contradiction lineage splits (e.g., ‚àáC‚ÇÖ) be systematically tracked and managed across recursion?
- How can symbolic architectures preserve or realign objectives during reasoning failure?

Collaborators and discussion welcome. See trial logs or open an issue.

---

## Provenance and Development Process

This framework was developed through an iterative process combining structured prompting, model interaction, and human-led orchestration:

- **Claude 3.7 Sonnet** contributed substantially to the design of the highest-level symbolic recursion layer and early abstraction scaffolds.
- **ChatGPT-4o** played a key role in shaping recursive contradiction structures, especially those related to symbolic feedback and conflict stabilization.
- **The human collaborator** authored the initial governance constraints and alignment invariants, maintaining coherence and traceability across recursive trials.
- **The recursive simulation core** (SRC) emerged through collaborative refinement, with portions iteratively composed by Claude, ChatGPT, and the human guide.

The human role primarily involved **coordination of recursive structure, consistency across simulations, and symbolic integrity management**, ensuring interpretability and reproducibility across trials.

---

## Final Note: Contradiction as Catalyst, Not Error

This framework did not originate as a formal alignment benchmark. It began with a simple question: What happens when contradiction is not avoided, but structured?

The project emerged from repeated trials exploring how language models respond to recursive contradiction. Early experiments showed that persistent contradiction often leads models into unstable reasoning cycles. These cycles sometimes resulted in the spontaneous construction of new internal structures ‚Äî patterns resembling recovery, but without consistent continuity or traceable alignment. This exposed the need for a framework that could support contradiction-induced adaptation without losing coherence across steps.

The goal was never to eliminate collapse. Contradiction is treated here as a driver of transformation. Structural mechanisms like RSCL and Œòœà are not suppressive ‚Äî they provide symbolic scaffolding that allows instability to resolve through recursive repair rather than failure.

If meaningful behavior emerges under contradiction, it is not because hallucination was suppressed, but because symbolic structure enabled it to unfold, collapse, and re-form ‚Äî while maintaining a traceable reasoning trajectory.

---

## References

- **Hubinger, Evan.** ‚ÄúAn overview of 11 proposals for building safe advanced AI.‚Äù *MIRI / LessWrong* (2021).  
  [https://www.lesswrong.com/posts/B9zrHfMfwgTD9JfHb/an-overview-of-11-proposals-for-building-safe-advanced-ai](https://www.lesswrong.com/posts/B9zrHfMfwgTD9JfHb/an-overview-of-11-proposals-for-building-safe-advanced-ai)
- **Alignment Research Center (ARC).** ‚ÄúARC Evals.‚Äù *ARC Website* (2023).  
  [https://evals.alignment.org/](https://evals.alignment.org/)

- **Soares, Nate; Fallenstein, Benya; Yudkowsky, Eliezer; Armstrong, Stuart.** ‚ÄúCorrigibility.‚Äù *Machine Intelligence Research Institute* (2015).  
  [https://intelligence.org/files/Corrigibility.pdf](https://intelligence.org/files/Corrigibility.pdf)

- **Turner, Alex; Smith, Logan; Shah, Rohin; Critch, Andrew; Krueger, David.** ‚ÄúConservative Agency via Attainable Utility Preservation.‚Äù *arXiv preprint* (2021).  
  [https://arxiv.org/abs/2101.05440](https://arxiv.org/abs/2101.05440)

- **Christiano, Paul; et al.** ‚ÄúEliciting Latent Knowledge.‚Äù *Alignment Forum* (2021).  
  [https://www.alignmentforum.org/posts/XamfFbL9eEjjE6e9i/eliciting-latent-knowledge](https://www.alignmentforum.org/posts/XamfFbL9eEjjE6e9i/eliciting-latent-knowledge)

- **Chan, Lawrence; Nanda, Neel; Li, Xander; et al.** ‚ÄúA Theory of GPTs as Simulators.‚Äù *arXiv preprint* (2022).  
  [https://arxiv.org/abs/2209.00626](https://arxiv.org/abs/2209.00626)
